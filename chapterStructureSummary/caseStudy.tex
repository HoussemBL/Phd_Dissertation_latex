
We have shown initially in Examples~\ref{par:example} and~\ref{par:example2} that our structure-based summary graph facilitates the task of understanding users' behaviour when exploring visually data using our system \prototype{}.
In this section, we broaden the discussion to show the feasibility of our instance when exploring visually other types of provenance.
Alongside the description of these scenarios, we illustrate the feasibility of some visual exploration tasks discussed in Section~\ref{sec:vis}.  
%Note that, we provide a set of structure-based summary graph visualizations associated to the discussed scenarios that are available online~\cite{usecase:url}. 
%\hou{the link is not anymore available}


\subsubsection{Visual debugging of a tracked process}

Assume that our goal is to define a university ranking that consolidates three well-known university rankings\footnote{\url{https://www.kaggle.com/mylesoneill/world-university-rankings}}. As the different source rankings use different criteria, the three source tables do not fully agree. Hence, consolidation requires the definition of a custom score derived from the three sources. Now, let us assume that the custom score yields some surprising results, e.g., the university ``MIT''  is ranked at tenth position. To better understand the working of the ranking, we compute the why-provenance of the suspicious result, as shown in Figure~\ref{fig:universityX1}.
This trace alone is not very insightful yet. To this end, we compute the structure-based summary graph that  includes traces for all results (we limit to 10 results in our example). 


Our structure-based summary graph, shown in Figure~\ref{fig:Inf-type-university1} %(and available online~\cite{usecase:url}) 
summarizes the ten why-provenance traces associated with the top-ten query results. 
\begin{figure}[t]
\center
\includegraphics[scale= 0.4]{figures/Tapp19/example_traceMIT1.pdf}
\caption{Provenance for MIT custom rank}
\label{fig:universityX1}
\end{figure}
\begin{figure}[t]
\center
\includegraphics[scale= 0.35]{figures/Tapp19/example_trace_summary1.pdf}
\caption{Structural summary of ten provenance traces}
\label{fig:Inf-type-university1}
\end{figure}

From this graph, we see (Task \mycircle{\scriptsize A}) that while most results (all conforming to the structure ``entitySt1'') are derived from entities conforming to the structure of ``entitySt2'', one entity is derived from a different structure, i.e., ``entitySt0''(Task \mycircle{\scriptsize D}). Interaction with this summary graph allows us to identify ``entitySt0'' as the structure of the unexpected ``MIT'' result. Hence, this summary shows that ``activity1'' computing the consolidated ranking may be affected by an incomplete input table (i.e., no score from the third source is available).



Indeed, it turns out that the use of a full outer join in our ranking query is unreliable as it tolerates the integration of incomplete information. Specifically, MIT university has a different name in one of the three ranking tables. 
This entails the presence of a tuple resulting from joining two ranking tables, used later to compute the final score of MIT university. 





\subsubsection{Data integration flow transparency}

Our second use case considers a data integration process specified using the high-level integration language (HIL)~\cite{hernandez:edbt13}  incorporated in IBM Infosphere Master Data Management\footnote{\url{https://www.ibm.com/support/knowledgecenter/SSWSR9_11.4.0/com.ibm.swg.im.mdmhs.pmebi.doc/topics/using_hil.html}}.
The sample integration flow extracts information about key people of the US financial sector. It takes a set of reports generated by companies to construct a set of individual reports about persons' careers.
HIL was recently instrumented to capture provenance~\cite{Oppold:IPAW18}, allowing us to generate five provenance traces tracking the discussed flow when integrating information about five persons.
%These traces are converted subsequently to PROV-JSON format and they are summarized using our approach.
These traces are converted subsequently to PROV-JSON format. 

Assume now that we are interested in understanding and learning recurrent patterns in the discussed sample integration flow. Accordingly, we can compare visually the five generated provenance graphs.
Yet, this process is tedious given the wealth of content of processed provenance traces.
To this end, we resort to our structure-based summary approach that can facilitate the task of understanding  the tracked data integration process.

 

As shown in Figure~\ref{fig:IBM}, we render the summary output by our approach using a force-directed graph (Task \mycircle{\scriptsize A}) given its capacity to place in convenient way vertices and edges by assigning forces to them.



\begin{figure}[t]
 \includegraphics[scale=0.4]{figures/tapp19/HIL_annotated2.pdf}
 \caption{Structural summary for HIL provenance graphs}
 \label{fig:IBM}
\end{figure}
The inspection of Figure~\ref{fig:IBM} reveals two important pieces of information. Firstly, we observe that the structure highlighted using an orange dashed box corresponds to the outcome of the implemented data integration flow as it is the only structure having only relationships of type ``generation'' with three activities structures. This reveals also that this particular structure was populated by three integration sub-flows (Task \mycircle{\scriptsize E}). By tracing back interactively these sub-flows, we can learn more about the implemented data integration flow.


Furthermore, Figure~\ref{fig:IBM} shows a second important finding. Indeed, all data integration sub-processes stem from the single structure highlighted by a green dashed box (Task \mycircle{\scriptsize F}). This later presents the structure of input reports used by the tracked data integration process. 
By hovering over the interactive visualization of Figure~\ref{fig:IBM}, 
%(available online~\cite{usecase:url}), 
we can learn the structure of input reports.
For instance, the input reports contain personal information about the key people including their address, their positions, as well as information related to the reports such as the issuer (the editor) of a report and the ID of the issuer.






\subsubsection{Corroboration}
Our final use case comes from the life science domain relating to Next Generation Sequencing (NGS) and is inspired by~\cite{alawini:18}. 
This project presents a workflow including six possible analysis stages that are invoked differently depending on the version of the workflow. 
One major problem already mentioned in~\cite{alawini:18} is the lack of NGS workflow transparency. Tackling this problem resulted in the collection of more than 800 provenance traces, which are publicly available\footnote{\url{https://github.com/alawinia/provClustering/}}. 

\begin{table}[t]
\centering
\scriptsize
\sffamily\footnotesize
\tabulinesep=2pt
 \begin{tabu}{|p{1.5cm}|p{8cm}|} \hline 
pattern & clause  \\\hline
claim & wasGeneratedBy$(e_1, a_1)$ with \newline $e_1= $\{"foaf:name":\{"\$":"file.txt", "type":"string"\},"prov:type":\{"\$": "kimlab","type":"qualified\_name" \}\},\newline $a_1:\{$"kimlab:htseq-stranded": \{"\$": "gencode2","type":"string"\}\} \\\hline
confirmation pattern & wasGeneratedBy$(e_1, a_1)$ with \newline  $e_1= \{$"foaf:name": \{"\$": *,"type":*\}, "prov:type":\{"\$": *,"type":* $\}\},\newline a_1=\{$"kimlab:htseq-stranded":\{"\$": *,"type":*\}$\}$ \\\hline
witness pattern & wasGeneratedBy$(e_1, a_1)$ with \newline $e_1=\{*\}, a_1=\{*\}$ \\\hline
\end{tabu}
\caption{Clauses used in the corroboration process}
\label{tab:rw}
\end{table}


We assume that an analyst is working on this collection to study impacts of analysis stages on the generated results.
 Given the large size of this collection, the analyst randomly picks some provenance traces. The analysis of these traces reveals the presence of common information presented in the first row of Table~\ref{tab:rw}.  This clause states that an analysis stage called ``HTSeq'' presented as an activity $a_1$ is always involved in the generation of some intermediate results. As it is tedious to check all provenance traces, \emph{the analyst claims that data input to the tracked workflow is necessarily processed by the analysis stage ``HTSeq''}.

To assess the truthfulness of the analyst's claim, we resort to the approach proposed in~\cite{Barakat:17}. 
It extracts the set of confirmation patterns (witnesses confirming the structure of the claim) and the set of witness patterns (generic version of the claim) from the existing provenance traces. The second and third rows of Table~\ref{tab:rw} describe these two sets, which are finally compared to compute the reliability of the claim. 

%Note that clauses of confirmation and witness patterns could be easily inferred using our approach. Hence, we generate the structure-based summary graph representative of provenance traces available in the analyzed repository.
Note that clauses of confirmation and witness patterns can be easily inferred using our approach. Hence, we use our approach to summarize provenance traces available in this provenance repository.



Figure~\ref{fig:corroboration} depicts an excerpt of the structure-based summary graph. We choose to only render  the set of structural relationships of type ``generation'' since they map to the witnesses set specified in the third row of Table~\ref{tab:rw} (Task \mycircle{\scriptsize E}). For that, we use a Sankey diagram as we need to highlight the cardinality of inferred relationships' structures that will be used to estimate the reliability of the claim.
\begin{figure}[t]
 \includegraphics[scale=0.4]{figures/tapp19/alawini_annotated.pdf}
 \caption{Excerpt of structural provenance summary graph}
 \label{fig:corroboration}
\end{figure}
Indeed, the width of edges in the Sankey diagram corresponds to the cardinality value of inferred relationships.
For instance, we can easily find the set of confirmation patterns (confirming the second row of Table~\ref{tab:rw}) which corresponds to the edge between nodes ``ActSt5'' and ``EntSt1''. The cardinality of this relationship is not high given the mediocre width of this particular edge. Based on this visualization, 
%(available in~\cite{usecase:url}), 
we can get a rough idea about the reliability of the claim (Task \mycircle{\scriptsize D}) which seems not high as the number of confirming patterns is significantly less than the number of witnesses (sum of all edges).
We can also learn interactively structures and exact cardinalities, that are used to compute the exact value of the reliability of the claim following formulas proposed in~\cite{Barakat:17}.


%\mel{This use case is not easily understandable when not already familiar with it. Maybe write from the perspective of a scientist? What are the questions they want to answer, e.g., is my claim correct, what frequent patterns exist? Then show how the structural summary helps to answer these questions.\\For all use cases, can you revisit why existing approaches are not useful for the type of analyis? This would then somehow serve as a qualitative evaluation (compared to existing approaches).}


